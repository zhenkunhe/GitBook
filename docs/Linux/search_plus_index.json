{"./":{"url":"./","title":"About","keywords":"","body":"READ ME © 2017 Trashman all right reserved，powered by Gitbook修訂時間： 2017-04-13 20:46:34 "},"tags.html":{"url":"tags.html","title":"tags","keywords":"","body":"Tags © 2017 Trashman all right reserved，powered by Gitbook修訂時間： 2017-04-13 20:46:34 "},"md/mininet/什麼是 mininet.html":{"url":"md/mininet/什麼是 mininet.html","title":"什麼是 mininet","keywords":"","body":"什麼是 mininet 什麼是 mininet mininet是一個用python寫的，跑在你的你電腦的一個Process 這個Process是一個網路模擬器(network emulator)，或者更精確的說：網路拓樸模擬器(network emulation orchestration system) 既然叫拓樸模擬器，代表它模擬了一整個: 終端主機(end-hosts) 路由器(router) 交換器(switches)的集成系統 模擬網路系統可以做什麼？ 通常透過mininet模擬的架構,會與實際透過硬體架設的結果一致，因此可做為實體配線前的臨摹 mininet模擬的host行為跟真的一樣：你可以SSH(Secure Shell)進去並運行任意程式，也可以運行server 你也可以送出封包，就像透過真的乙太網路出去，有link speed & delay，可以觀察封包來往的狀況 可以輕易的製作支援SDN的區域網路 (後面會介紹什麼是SDN)，事實上，mininet是很適合作為一個輕量級的SDN仿真工具 © 2017 Trashman all right reserved，powered by Gitbook修訂時間： 2017-07-05 18:15:50 "},"md/mininet/什麼是 SDN.html":{"url":"md/mininet/什麼是 SDN.html","title":"什麼是 SDN","keywords":"","body":"什麼是 SDN 什麼是 SDN？ 全名是：軟體定義式網路（Software defined Networking，SDN） 要了解SDN之前，要先了解現今網路架構中，路由器除了硬體上俱備有轉送資料的能力外， 對於資料的移動控制，都是在每一台路由器中，實作著遵守各種傳輸協定的控制軟體 例如連結層有擴展樹協定（Spanning Tree Protocol，STP）來防止封包卡在迴圈 雖然協定是共通的，但網通廠商各有各的OS與實作技術，導致一旦企業購買某一廠牌的設備， 未來更新設備時就必須遷就於該廠牌的網管功能，造成被網通廠商挾持的情形 現今這樣不是沒什麼問題嘛？ 隨著隨著雲端應用及巨量資料增加，路由表越來越龐大，判斷轉送的過程愈來愈複雜 而這些判斷需要路徑上的每一台交換器或是路由器不斷的拆分及重組封包 可想而知，結果導致傳輸效率不佳，無法有效發揮網路頻寬 網路管理人員需要客製調整各種網路設定時，也必須針對每臺交換器或路由器，逐一登入command-line設定，相當麻煩 而且透過人工逐一設定的方式也有很高的風險，一旦網路管理人員輸入了錯誤的指令，很容易造成網路服務癱瘓 於是關於控制封包這件事情，我們需要重新思考：真的需要每一台路由器拆開封包才能判斷嘛？ 所以SDN做了什麼？ 它的概念是：將網路分為控制層（Control Plane）與資料層（Data Plane） 將網路的管理權限交由控制層的控制器（Controller）軟體負責，採用集中控管的方式，同時也負責決定傳輸路徑 Image 2.2.1 - SDN SDN帶來的好處？ 讓網路的管理變得更集中 自動處理與動態因應變化 讓網路的設計、部署、管理、規模延展更為容易 可以減少IT服務日常維運，減少人為出錯 既然傳輸路徑已預先設定完成，交換器不需要透過不斷學習來尋找封包傳送的路徑，可大幅提升傳輸效率，降低延遲（Latency）的時間 可節省支出 所以網通廠怎麼看SDN？ SDN使得交換器的重要性將會不如以往 (功能會越來越單純，未來可能僅負責封包的傳送) 未來客製化的軟體就可以提供各項硬體設備的功能 於硬體設備廠商來說，將會是一大衝擊 臺灣企業還不了解SDN在未來的重要性，而且開發SDN應用程式的門檻較高 Google、Facebook、Yahoo、微軟等多家指標型的大企業投入了SDN架構與OpenFlow技術的發展 我剛好像看到OpenFlow，那是什麼？ 跟SDN是什麼關係 OpenFlow是實現SDN架構最主流的核心技術，也就是網路交換器(switch)和控制器(controller)之間的傳輸協定 就像是人類的神經一樣，負責大腦與四肢的溝通 OpenFlow技術將封包傳送的路徑看成是一條「Flow」，就好像是專屬的傳輸路徑 例如經過哪些交換器，需要多少的網路頻寬，再將傳輸路徑設定成OpenFlow路由表（Flow Table） 控制層和資料層之間，利用SSL加密，建立起安全的傳輸通道 但它只是整體SDN架構的一部分，而且也並非唯一可用的協定 OpenFlow是SDN的一部分，但SDN不是只有OpenFlow Image 2.2.2 - OpenFlow © 2017 Trashman all right reserved，powered by Gitbook修訂時間： 2017-07-05 18:17:08 "},"md/mininet/mininet 實戰.html":{"url":"md/mininet/mininet 實戰.html","title":"mininet 實戰","keywords":"","body":"mininet 實戰 安裝 Debian Package sudo apt-get install mininet Build source and install git clone git://github.com/mininet/mininet mininet/util/install.sh -a 啟動 sudo mn Image 2.3.1 - mn mininet是基於OVS的應用軟體，當沒有設定OVS Controller時，他會退回OVS Bridge模式(不依賴Controller，預設所有node都是可以連通的) OVS:全名Open vSwitch，類似VM，主要是虛擬switch，支援OpenFlow 在沒有任何參數下，產生的虛擬環境為兩個host (h1,h2)，一個switch (s1)，並將h1,h2連接s1 Image 2.3.2 - Topology 測試 顯示所有節點:nodes Image 2.3.3 - nodes 顯示所有節點的連接關係:net Image 2.3.4 - net 察看所有節點的資訊:dump Image 2.3.5 - dump 用h1 ping h2 一個封包:h1 ping -c 1 h2 Image 2.3.6 - ping 叫出兩個host的命令視窗:xterm h1 h2 Image 2.3.7 - xterm 寫一個Python範例 目標 啟動50個hosts，作為VM server farm 啟動1個controller 啟動1個switch Image 2.3.8 - Server Farm Code example #!/usr/bin/python import re from mininet.net import Mininet from mininet.node import Controller from mininet.cli import CLI from mininet.link import Intf from mininet.log import setLogLevel, info, error from mininet.util import quietRun from mininet.node import OVSController def checkIntf( intf ): \"Make sure intf exists and is not configured.\" if ( ' %s:' % intf ) not in quietRun( 'ip link show' ): error( 'Error:', intf, 'does not exist!\\n' ) exit( 1 ) ips = re.findall( r'\\d+\\.\\d+\\.\\d+\\.\\d+', quietRun( 'ifconfig ' + intf ) ) if ips: error( 'Error:', intf, 'has an IP address and is probably in use!\\n' ) exit( 1 ) def myNetwork(): net = Mininet( topo=None, build=False) info( '*** Adding controller\\n' ) net.addController(name='c0',controller = OVSController) info( '*** Add switches\\n') s1 = net.addSwitch('s1') max_hosts = 50 newIntf = 'enp3s0' host_list = {} info( '*** Add hosts\\n') for i in xrange(1,max_hosts+1): host_list[i] = net.addHost('h'+str(i)) info( '*** Add links between ',host_list[i],' and s1 \\r') net.addLink(host_list[i], s1) info( '*** Checking the interface ', newIntf, '\\n' ) checkIntf( newIntf ) switch = net.switches[ 0 ] info( '*** Adding', newIntf, 'to switch', switch.name, '\\n' ) brintf = Intf( newIntf, node=switch ) info( '*** Starting network\\n') net.start() CLI(net) net.stop() if __name__ == '__main__': setLogLevel( 'info' ) myNetwork() 執行 sudo python example.py 問題 Q:執行出現Cannot find required executable ovs-controller A:你沒有安裝ovs-controllersudo apt-get install openvswitch-testcontroller而ovs-controller是舊名稱，所以你需要複製一下sudo cp /usr/bin/ovs-testcontroller /usr/bin/ovs-controller Q:執行出現 Exception: Please shut down the controller which is running on port 6653: Active Internet connections (servers and established) tcp 0 0 0.0.0.0:6653 0.0.0.0:* LISTEN 30215/ovs-testcontr A:你需要kill正在背景執行的ovs-testcontrollersudo netstat -lptusudo service ovs-testcontroller stop Mininet Python API Topo: the base class for Mininet topologies build(): The method to override in your topology class. Constructor parameters (n) will be passed through to it automatically by Topo.init(). addSwitch(): adds a switch to a topology and returns the switch name addHost(): adds a host to a topology and returns the host name addLink(): adds a bidirectional link to a topology (and returns a link key, but this is not important). Links in Mininet are bidirectional unless noted otherwise. Mininet: main class to create and manage a network start(): starts your network pingAll(): tests connectivity by trying to have all nodes ping each other stop(): stops your network net.hosts: all the hosts in a network dumpNodeConnections(): dumps connections to/from a set of nodes. setLogLevel( 'info' | 'debug' | 'output' ): set Mininet's default output level; 'info' is recommended as it provides useful information. © 2017 Trashman all right reserved，powered by Gitbook修訂時間： 2017-07-05 18:05:46 "},"md/mininet/運作原理.html":{"url":"md/mininet/運作原理.html","title":"運作原理","keywords":"","body":"運作原理 Network Namespace Node Link Interface © 2017 Trashman all right reserved，powered by Gitbook修訂時間： 2017-07-05 18:06:33 "},"md/mininet/運作原理/Network Namespace.html":{"url":"md/mininet/運作原理/Network Namespace.html","title":"Network Namespace","keywords":"","body":"Network Namespace Mininet虛擬化的核心機制是？ Linux Network Namespace是Mininet軟體架構的基石，用其創建虛擬節點 需要先了解Linux Namespace 之中的 Network Namespaces 其實Linux Network Namespace在OpenStack和Docker等開源項目中也廣泛應用主要用於作業系統層級的虛擬化，包含虛擬網路 預設情況下，Mininet會為每一個host創建一個新的Network Namespaces 由於每個host都有各自獨立的Network Namespaces，我們就可以進行個性化的網路配置和程式佈署 在root Namespace運行switch和controllerProcess，因此兩個Processes共享同一個Network Namespaces 由於Linux Namespace的虛擬技術沒有提供類似於VM的持久化能力，所以在Mininet關閉時不能保存所有設定 Mininet創建的Network namespace是nameless的，所以透過ip netns listcommand是查看不到的 而透過ip netns addcommand創建的Network Namespace是帶name的，這是兩者最明顯的區別之處Discussions /* */ #mermaidChart0 .node>rect { ; } #mermaidChart0 .node text { fill:#000; stroke:none; font-weight:300; font-family:\"Helvetica Neue\",Helvetica,Arial,sans-serf; font-size:14px; } #mermaidChart0 .edgeLabel text { fill:#000; stroke:none; font-weight:300; font-family:\"Helvetica Neue\",Helvetica,Arial,sans-serf; font-size:14px; } #mermaidChart0 .cluster rect { rx:4px; fill: rgb(255, 255, 222); rx: 4px; stroke: rgb(170, 170, 51); stroke-width: 1px; } .mermaid .label { color: rgb(51, 51, 51); } .node rect, .node circle, .node ellipse, .node polygon { fill: #ececff; stroke: #ccccff; stroke-width: 1px; } .edgepath .path { stroke: #333333; } .cluster rect { fill: #ffffde !important; stroke: #aaaa33 !important; stroke-width: 1px !important; } .cluster text { fill: #333333; } text { font-family: 'trebuchet ms', verdana, arial; font-size: 14px; } /* */ Root namespace No namenamespace No namenamespaceTwo lineedge commentTwo lineedge commentOpenvSwitchs1Hosth1Hosth2 在如下的示例中，兩個虛擬主機H1和H2連接到交換機S1，通過Bash來模擬H1和H2，交換機S1運行在Linux內核運行的root namespace 。H1和H2就擁有自己的網絡命名空間以及私有網絡接口h1-eth0和h2-eth0。 交換機S1有兩個埠s1-eth1和s1-eth2，通過veth pair與對應的主機接口相連，這樣H1和H2就可以通過S1進行通信。 s1-eth0和s1-eth1間的數據包轉發通過軟體交換機完成，它運行在root namespace並使用物理接口eth0，等待控制器的指令。 © 2017 Trashman all right reserved，powered by Gitbook修訂時間： 2017-07-06 14:41:30 "},"md/mininet/運作原理/Node.html":{"url":"md/mininet/運作原理/Node.html","title":"Node","keywords":"","body":"Node 每個Host其實就是一個Node的物件，可以在node.py中看到此物件的定義，如下。 在node.py class Node( object ): \"\"\"A virtual network node is simply a shell in a network namespace. We communicate with it using pipes.\"\"\" portBase = 0 # Nodes always start with eth0/port0, even in OF 1.0 def __init__( self, name, inNamespace=True, **params ): \"\"\"name: name of node inNamespace: in network namespace? privateDirs: list of private directory strings or tuples params: Node parameters (see config() for details)\"\"\" # Make sure class actually works self.checkSetup() self.name = params.get( 'name', name ) self.privateDirs = params.get( 'privateDirs', [] ) self.inNamespace = params.get( 'inNamespace', inNamespace ) # Stash configuration parameters for future reference self.params = params self.intfs = {} # dict of port numbers to interfaces self.ports = {} # dict of interfaces to port numbers # replace with Port objects, eventually ? self.nameToIntf = {} # dict of interface names to Intfs # Make pylint happy ( self.shell, self.execed, self.pid, self.stdin, self.stdout, self.lastPid, self.lastCmd, self.pollOut ) = ( None, None, None, None, None, None, None, None ) self.waiting = False self.readbuf = '' # Start command interpreter shell self.startShell() self.mountPrivateDirs() # File descriptor to node mapping support # Class variables and methods inToNode = {} # mapping of input fds to nodes outToNode = {} # mapping of output fds to nodes 這邊可以看到，這邊會有一個變數inNamespace用來決定此Host是否要透過network namespaces來達到network isolation的功能，當一切變數都初始化後，就會呼叫startShell()來執行此Host。 node.py def startShell( self, mnopts=None ): \"Start a shell process for running commands\" if self.shell: error( \"%s: shell is already running\\n\" % self.name ) return # mnexec: (c)lose descriptors, (d)etach from tty, # (p)rint pid, and run in (n)amespace opts = '-cd' if mnopts is None else mnopts if self.inNamespace: opts += 'n' # bash -i: force interactive # -s: pass $* to shell, and make process easy to find in ps # prompt is set to sentinel chr( 127 ) cmd = [ 'mnexec', opts, 'env', 'PS1=' + chr( 127 ), 'bash', '--norc', '-is', 'mininet:' + self.name ] # Spawn a shell subprocess in a pseudo-tty, to disable buffering # in the subprocess and insulate it from signals (e.g. SIGINT) # received by the parent master, slave = pty.openpty() self.shell = self._popen( cmd, stdin=slave, stdout=slave, stderr=slave, close_fds=False ) self.stdin = os.fdopen( master, 'rw' ) self.stdout = self.stdin self.pid = self.shell.pid self.pollOut = select.poll() self.pollOut.register( self.stdout ) # Maintain mapping between file descriptors and nodes # This is useful for monitoring multiple nodes # using select.poll() self.outToNode[ self.stdout.fileno() ] = self self.inToNode[ self.stdin.fileno() ] = self self.execed = False self.lastCmd = None self.lastPid = None self.readbuf = '' # Wait for prompt while True: data = self.read( 1024 ) if data[ -1 ] == chr( 127 ): break self.pollOut.poll() self.waiting = False # +m: disable job control notification self.cmd( 'unset HISTFILE; stty -echo; set +m' ) 這邊可以觀察到，mininet是透過一隻叫做mnexec的程式來執行 mnexec 透過參數-n來將此process給轉換到network namespaces中 當初始化兩個Host後，系統中就會出現了兩個Host，且這兩個host都會透過namespace來達到network isolation， 理論上我們要可以透過ip netns show來看到這些namespaces，實際上卻看不到，原因如同此篇所說。 https://mailman.stanford.edu/pipermail/mininet-discuss/2014-January/003796.html 此時，我們的系統如下 創立好Host後，接下來要創立Switch Switch有很多種選擇，包含了OVSLegacyKernelSwitch、UserSwitch、OVSSwitch，IVSSwitch此四種， 一般常用的就是OVSSwitch 這四種Switch都繼承自Switch物件，而Switch物件則繼承自Node Switch OVSLegacyKernelSwitch UserSwitch OVSSwitch IVSSwitch 此時系統如下，系統中已經創立好了switch以及兩個host，這三個Node都分別透過namespace來達到了network isolation，只是彼此之間都尚未有任何Link存在。 © 2017 Trashman all right reserved，powered by Gitbook修訂時間： 2017-04-13 20:46:34 "},"md/mininet/運作原理/Link.html":{"url":"md/mininet/運作原理/Link.html","title":"Link","keywords":"","body":"Link 接下來，會根據拓墣的Link情況去創建對應的Iterface。首先，這邊使用到Link這個物件來表示每一條Link，每個Link實際上對應到的是兩個Node上面的Interface。 link.py class Link( object ): \"\"\"A basic link is just a veth pair. Other types of links could be tunnels, link emulators, etc..\"\"\" # pylint: disable=too-many-branches def __init__( self, node1, node2, port1=None, port2=None, intfName1=None, intfName2=None, addr1=None, addr2=None, intf=Intf, cls1=None, cls2=None, params1=None, params2=None, fast=True ): \"\"\"Create veth link to another node, making two new interfaces. node1: first node node2: second node port1: node1 port number (optional) port2: node2 port number (optional) intf: default interface class/constructor cls1, cls2: optional interface-specific constructors intfName1: node1 interface name (optional) intfName2: node2 interface name (optional) params1: parameters for interface 1 params2: parameters for interface 2\"\"\" # This is a bit awkward; it seems that having everything in # params is more orthogonal, but being able to specify # in-line arguments is more convenient! So we support both. if params1 is None: params1 = {} if params2 is None: params2 = {} # Allow passing in params1=params2 if params2 is params1: params2 = dict( params1 ) if port1 is not None: params1[ 'port' ] = port1 if port2 is not None: params2[ 'port' ] = port2 if 'port' not in params1: params1[ 'port' ] = node1.newPort() if 'port' not in params2: params2[ 'port' ] = node2.newPort() if not intfName1: intfName1 = self.intfName( node1, params1[ 'port' ] ) if not intfName2: intfName2 = self.intfName( node2, params2[ 'port' ] ) self.fast = fast if fast: params1.setdefault( 'moveIntfFn', self._ignore ) params2.setdefault( 'moveIntfFn', self._ignore ) self.makeIntfPair( intfName1, intfName2, addr1, addr2, node1, node2, deleteIntfs=False ) 這邊要觀察到的，Link物件會呼叫makeIntfPair此方法，此方法就可以將兩個Interface給串接起來 util.py def makeIntfPair( intf1, intf2, addr1=None, addr2=None, node1=None, node2=None, deleteIntfs=True, runCmd=None ): \"\"\"Make a veth pair connnecting new interfaces intf1 and intf2 intf1: name for interface 1 intf2: name for interface 2 addr1: MAC address for interface 1 (optional) addr2: MAC address for interface 2 (optional) node1: home node for interface 1 (optional) node2: home node for interface 2 (optional) deleteIntfs: delete intfs before creating them runCmd: function to run shell commands (quietRun) raises Exception on failure\"\"\" if not runCmd: runCmd = quietRun if not node1 else node1.cmd runCmd2 = quietRun if not node2 else node2.cmd if deleteIntfs: # Delete any old interfaces with the same names runCmd( 'ip link del ' + intf1 ) runCmd2( 'ip link del ' + intf2 ) # Create new pair netns = 1 if not node2 else node2.pid if addr1 is None and addr2 is None: cmdOutput = runCmd( 'ip link add name %s ' 'type veth peer name %s ' 'netns %s' % ( intf1, intf2, netns ) ) else: cmdOutput = runCmd( 'ip link add name %s ' 'address %s ' 'type veth peer name %s ' 'address %s ' 'netns %s' % ( intf1, addr1, intf2, addr2, netns ) ) if cmdOutput: raise Exception( \"Error creating interface pair (%s,%s): %s \" % ( intf1, intf2, cmdOutput ) ) 這邊可以看到，mininet實際上是透過系統中的ip link的方法將兩個interface創造一條veth的Link。 此時系統如下 © 2017 Trashman all right reserved，powered by Gitbook修訂時間： 2017-04-13 20:46:34 "},"md/mininet/運作原理/Interface.html":{"url":"md/mininet/運作原理/Interface.html","title":"Interface","keywords":"","body":"Interface 接下來，我們要把這些interface給綁到特定的Node身上，在Link物件初始化後段，會去初始化兩個Interface真正的物件本體， link.py class Intf( object ): \"Basic interface object that can configure itself.\" def __init__( self, name, node=None, port=None, link=None, mac=None, **params ): \"\"\"name: interface name (e.g. h1-eth0) node: owning node (where this intf most likely lives) link: parent link if we're part of a link other arguments are passed to config()\"\"\" self.node = node self.name = name self.link = link self.mac = mac self.ip, self.prefixLen = None, None # if interface is lo, we know the ip is 127.0.0.1. # This saves an ifconfig command per node if self.name == 'lo': self.ip = '127.0.0.1' # Add to node (and move ourselves if necessary ) moveIntfFn = params.pop( 'moveIntfFn', None ) if moveIntfFn: node.addIntf( self, port=port, moveIntfFn=moveIntfFn ) else: node.addIntf( self, port=port ) # Save params for future reference self.params = params self.config( **params ) 這邊要觀察的重點是每個Interface都會去呼叫node.addIntf( self, port=port )來處理 node.py def addIntf( self, intf, port=None, moveIntfFn=moveIntf ): \"\"\"Add an interface. intf: interface port: port number (optional, typically OpenFlow port number) moveIntfFn: function to move interface (optional)\"\"\" if port is None: port = self.newPort() self.intfs[ port ] = intf self.ports[ intf ] = port self.nameToIntf[ intf.name ] = intf debug( '\\n' ) debug( 'added intf %s (%d) to node %s\\n' % ( intf, port, self.name ) ) if self.inNamespace: debug( 'moving', intf, 'into namespace for', self.name, '\\n' ) moveIntfFn( intf.name, self ) 此方法最後會呼叫 moveIntf 來將該interface給處理，moveIntf則會呼叫moveIntfNoRetry將Interface給綁入到每個Node中 util.py def moveIntf( intf, dstNode, printError=True, retries=3, delaySecs=0.001 ): \"\"\"Move interface to node, retrying on failure. intf: string, interface dstNode: destination Node printError: if true, print error\"\"\" retry( retries, delaySecs, moveIntfNoRetry, intf, dstNode, printError=printError ) def moveIntfNoRetry( intf, dstNode, printError=False ): \"\"\"Move interface to node, without retrying. intf: string, interface dstNode: destination Node printError: if true, print error\"\"\" intf = str( intf ) cmd = 'ip link set %s netns %s' % ( intf, dstNode.pid ) cmdOutput = quietRun( cmd ) # If ip link set does not produce any output, then we can assume # that the link has been moved successfully. if cmdOutput: if printError: error( '*** Error: moveIntf: ' + intf + ' not successfully moved to ' + dstNode.name + ':\\n', cmdOutput ) return False return True 邊可以看到，透過的指令則是ip link set %s netns %s，會將特定的interface給塞入特定Node的namespace之中 此時，我們的系統如下 OVSSwitch透過ovs-vsctl add-port將Switch上面的Interface都給OVS控管 node.py def attach( self, intf ): \"Connect a data port\" self.vsctl( 'add-port', self, intf ) self.cmd( 'ifconfig', intf, 'up' ) self.TCReapply( intf ) def vsctl( self, *args, **kwargs ): \"Run ovs-vsctl command (or queue for later execution)\" if self.batch: cmd = ' '.join( str( arg ).strip() for arg in args ) self.commands.append( cmd ) else: return self.cmd( 'ovs-vsctl', *args, **kwargs ) © 2017 Trashman all right reserved，powered by Gitbook修訂時間： 2017-04-13 20:46:34 "},"md/Namespace/簡介.html":{"url":"md/Namespace/簡介.html","title":"簡介","keywords":"","body":"簡介 什麼是Namespace？ 命名空間就是在大箱子(Kernel)裏面再裝一堆小箱子(Kernel Namespace) 為什麼要這麼做？ 因為如果我們想在箱子裏面放兩個外觀一模一樣的蘋果(Process)，到時候一定會無法區分不如就放在A箱子裡面的蘋果，叫作A蘋果；放在B箱子裡面的蘋果，叫作B蘋果 命名空間有幾種？ Linux 2.6.24版的Kernel開始,提供了6種不同類型的Namespace分別是： 程序間通信(IPC)命名空間 程序命名空間 網絡命名空間 掛載命名空間 UTS命名空間 用戶命名空間 所以有人說Namespaces是一種資源隔離方案，使得PID、Network、IPC等系統資源，不再屬於全域設定，而是某個特定的Namespace的資源。 還有其他好處嘛？ 通過Namespace技術使得用戶創建的程序能夠與系統分離得更加徹底，從而不需要使用更多的底層(硬體支援)虛擬化技術因為Namespaces是用純軟體劃分出來的概念 Namespace之間有關聯嘛？ Namespace之間的資源互相隔離、不可見的因此在作業系統層面上看，就會出現多個相同pid的進程 User要怎麼看待Namespace 在用戶層面上只能看到屬於用戶自己Namespace下的資源例如使用ps命令只能列出自己Namespace下的程序使用者角度來看,每個Namespace看上去就像一個單獨的Linux系統 Image 3.1.1 - Linux的命名空間技術架構 © 2017 Trashman all right reserved，powered by Gitbook修訂時間： 2017-04-13 20:46:34 "},"md/Namespace/Network namespaces.html":{"url":"md/Namespace/Network namespaces.html","title":"Network namespaces","keywords":"","body":"Network namespaces 介紹什麼是Network Namespace 使用範例 © 2017 Trashman all right reserved，powered by Gitbook修訂時間： 2017-07-05 11:19:10 "},"md/Namespace/Network namespaces/什麼是Network Namespace.html":{"url":"md/Namespace/Network namespaces/什麼是Network Namespace.html","title":"什麼是Network Namespace","keywords":"","body":"什麼是Network Namespace 什麼是Network namespace 虛擬化網路相關的功能 Linux近幾年特有的技術(Darwin/Windows無類似功能)(約Kernel 3.0開始才有) 是輕量級虛擬化技術的基礎（Docker,LXC,OpenVZ的根本原理） 多用在虛擬化和隔離 很少被單獨使用 虛擬化網路相關的功能,是指哪些？ 不同Network namespace內的Process,具有不同的Network資源如下： 虛擬網卡列表 IPv4和IPv6協議 Routing Table 防火牆設定 /proc/net目錄 /sys/class/net目錄 埠（socket） 有什麼特性？ 讓一個或多個Process之間搞小團體小團體內有私有網路資源，小團體間互不干擾所以多用在虛擬化和隔離 如果Network Namespace之間要互相溝通怎麼辦? 通過創建veth pair（虛擬網路設備對接口）在不同的Network namespace間創建通道不同Network Namespace因此得以共享同一個實體網路設備 傳統沒有Network namespace前是怎樣？ 一般乙太網路應用程式 Image 3.2.1.1 - 一般乙太網路應用程式 如果是ADSL/光世代的PPPoE Image 3.2.1.2 - PPPoE 如果是VPN Image 3.2.1.3 - VPN 網卡拿來當Hub用的Bridge Image 3.2.1.4 - Bridge Bridge相關指令: 需要安裝bridge-utils才能使用brctl brctl show - 顯示bridge狀況 brctl addbr/delbr - 新增/刪除bridge brctl addif - 將interface新增至bridge brctl delif - 將interface從bridge移除 有Network namespace後是怎樣？ 只有一個Network namespace的話 Image 3.2.1.5 - 一個Network namespace 複數Network namespace的話 Image 3.2.1.6 - 複數Network namespace 透過veth可以連接兩個Network namespace Image 3.2.1.7 - veth 搭配Bridge使其他Network namespace上網 Image 3.2.1.8 - Bridge+Network namespace 有什麼應用場景？ 多個Network namespace可以共享eth0和lo等實體網路設備 多個Apache伺服器Process可以在不同Network namespace的80埠上進行監聽 一個Process不能嗅探其他Network namespace的流量 一個Process不能關閉其他Network namespace的接口 © 2017 Trashman all right reserved，powered by Gitbook修訂時間： 2017-04-13 20:46:34 "},"md/Namespace/Network namespaces/範例.html":{"url":"md/Namespace/Network namespaces/範例.html","title":"範例","keywords":"","body":"範例 此範例的目標是？ 通過ip這個command創建H1和H2兩個Network namespace H1擁有自己的Network namespace以及私有網路網路接口h1-eth0 H2擁有自己的Network namespace以及私有網路網路接口h2-eth0 軟體Switch S1有兩個埠s1-eth0和s1-eth1 通過veth pair與對應的主機接口相連，這樣H1和H2就可以通過S1進行通信 s1-eth0和s1-eth1間的通訊資料通過軟體Switch轉發它運行在root namespace,並使用實體接口eth0，等待控制器的指令 Image 3.2.2.1 - Example1 什麼是ip command? ip這個command是iproute2軟體包裡面的一個強大的網路配置工具它能夠替代一些傳統的網路管理工具 例如:ifconfigroute 使用權限要為root幾乎所有的Linux發行版本都支持該command 介紹ip command吧 ip netns add - 新增NetNS ip netns list - 列出現有的NetNS ip netns identify - 顯示PID所在的NetNS ip netns identify $$ - 顯示目前的NetNS ip netns exec - 在NetNS執行command ip link add type veth peer name - 建立一個veth裝置 ip link set nets - 將veth 搬到NetNS Step 1 - Create host namespaces $ sudo ip netns add h1 $ sudo ip netns add h2 $ sudo ip netns Image 3.2.2.2 - Step 1-Result Image 3.2.2.3 - Step 1-Topo Step 2 - Create switch $ sudo ovs-vsctl add-br s1 Image 3.2.2.4 - Step 2-Topo Step 3 - Create links $ sudo ip link add h1-eth0 type veth peer name s1-eth1 $ sudo ip link add h2-eth0 type veth peer name s1-eth2 $ sudo ip link show Image 3.2.2.5 - Step 3-Result Step 4 - Move host ports into namespaces $ sudo ip link set h1-eth0 netns h1 $ sudo ip link set h2-eth0 netns h2 $ sudo ip netns exec h1 ip link show $ sudo ip netns exec h2 ip link show Image 3.2.2.6 - Step 4-Result Image 3.2.2.7 - Step 4-Topo Step 5 - Connect switch ports to OVS $ sudo ovs-vsctl add-port s1 s1-eth1 $ sudo ovs-vsctl add-port s1 s1-eth2 $ sudo ovs-vsctl show Image 3.2.2.8 - Step 5-Topo Step 6 - Set up OpenFlow controller $ sudo ovs-vsctl set-controller s1 tcp:127.0.0.1 $ sudo ovs-controller ptcp: $ sudo ovs-vsctl show Image 3.2.2.9 - Step 6-Result Step 7 - Configure network $ sudo ip netns exec h1 ifconfig h1-eth0 10.1 $ sudo ip netns exec h1 ifconfig lo up $ sudo ip netns exec h2 ifconfig h2-eth0 10.2 $ sudo ip netns exec h2 ifconfig lo up $ sudo ifconfig s1-eth1 up $ sudo ifconfig s1-eth2 up Step 8 - Test network $ sudo ip netns exec h1 ping -c1 10.2 Image 3.2.2.10 - Step 8-Result Image 3.2.2.11 - Final-Result © 2017 Trashman all right reserved，powered by Gitbook修訂時間： 2017-07-05 17:57:15 "},"md/Docker/簡介.html":{"url":"md/Docker/簡介.html","title":"簡介","keywords":"","body":"簡介 sudo docker run -it --privileged -v /dev/bus/usb:/dev/bus/usb ubuntu:14.04 /bin/bash sudo docker exec -u root -it compassionate_snyder bash 'su' command in Docker returns 'must be run from terminal' When you are ssh-ing in or going in via php your session is not being allocated a pty. I have used each of the following solutions: ANSWER 3: use python to spawn a pty in your shell Quite a cute hack :) jenkins@e9fbe94d4c89:~$ su - su: must be run from a terminal $ echo \"import pty; pty.spawn('/bin/bash')\" > /tmp/asdf.py $ python /tmp/asdf.py $ su - Password: root@e9fbe94d4c89:~# © 2017 Trashman all right reserved，powered by Gitbook修訂時間： 2017-06-20 17:25:08 "}}